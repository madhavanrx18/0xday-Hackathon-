{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhavanrx18/0xday-Hackathon-/blob/main/Partial_Homomorphic_Encryption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from phe import paillier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/output_file.csv')\n",
        "\n",
        "df['age'] = df['age'] / 365.25\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df = df.drop(columns=['Name', 'Phone Number'])\n",
        "\n",
        "# Encode categorical columns\n",
        "categorical_columns = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
        "encoder = LabelEncoder()\n",
        "for col in categorical_columns:\n",
        "    df[col] = encoder.fit_transform(df[col])\n",
        "\n",
        "# Normalize numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(columns=['cardio']).values\n",
        "y = df['cardio'].values\n",
        "\n",
        "# Step 3: Split the dataset into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
        "\n",
        "# Step 4: Standardize the numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # Standardize training features\n",
        "X_test_scaled = scaler.transform(X_test)  # Standardize test features based on the training data\n",
        "\n",
        "# Step 5: Train the Logistic Regression model on non-encrypted data\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 6: Get the model weights and intercept\n",
        "weights = model.coef_.flatten()  # Coefficients of the logistic regression model\n",
        "intercept = model.intercept_[0]  # Intercept of the model\n",
        "\n",
        "# Step 7: Encrypt the weights and intercept using Paillier encryption\n",
        "public_key, private_key = paillier.generate_paillier_keypair()\n",
        "\n",
        "# Encrypt the intercept\n",
        "encrypted_b = public_key.encrypt(intercept)\n",
        "\n",
        "# Step 8: Encrypt the test data (X_test)\n",
        "# Encrypt each feature individually\n",
        "encrypted_X_test = []\n",
        "for row in X_test_scaled:\n",
        "    encrypted_row = [public_key.encrypt(x) for x in row]\n",
        "    encrypted_X_test.append(encrypted_row)\n",
        "\n",
        "# Step 9: Compute the dot product w * X normally and then encrypt it\n",
        "# Compute dot product (w * X) in the plaintext domain\n",
        "dot_product = np.dot(X_test_scaled, weights)\n",
        "\n",
        "# Encrypt the dot product\n",
        "encrypted_dot_product = [public_key.encrypt(a) for a in dot_product]\n",
        "\n",
        "# Step 10: Perform encrypted inference (dot product + intercept)\n",
        "def encrypted_inference(encrypted_dot_product, encrypted_b, public_key):\n",
        "    \"\"\"\n",
        "    Perform inference on encrypted data without decrypting it.\n",
        "\n",
        "    Parameters:\n",
        "    - encrypted_dot_product: Encrypted dot product values (w * X).\n",
        "    - encrypted_b: Encrypted intercept (b).\n",
        "    - public_key: Public key for performing homomorphic operations.\n",
        "\n",
        "    Returns:\n",
        "    - List of encrypted predictions (0 or 1).\n",
        "    \"\"\"\n",
        "    encrypted_predictions = []\n",
        "    for encrypted_a in encrypted_dot_product:\n",
        "        # Add the encrypted intercept to the encrypted dot product\n",
        "        encrypted_sum = encrypted_a + encrypted_b\n",
        "\n",
        "        # Apply decision boundary: If sum > 0, predict 1, else predict 0\n",
        "        encrypted_pred = public_key.encrypt(1) if private_key.decrypt(encrypted_sum) > 0 else public_key.encrypt(0)\n",
        "        encrypted_predictions.append(encrypted_pred)\n",
        "\n",
        "    return encrypted_predictions\n",
        "\n",
        "# Step 11: Compute the encrypted predictions for the test dataset\n",
        "encrypted_predictions = encrypted_inference(encrypted_dot_product, encrypted_b, public_key)\n",
        "\n",
        "# Step 12: Decrypt the predictions to get the final result\n",
        "decrypted_predictions = [private_key.decrypt(pred) for pred in encrypted_predictions]\n",
        "\n",
        "# Step 13: Calculate the accuracy metrics\n",
        "accuracy = accuracy_score(y_test, decrypted_predictions)\n",
        "\n",
        "# Print the decrypted predictions and the accuracy\n",
        "print(\"Decrypted predictions:\", decrypted_predictions)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obIil-QDfJOD",
        "outputId": "7e97263d-fca6-4502-b998-85f4f2a60649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decrypted predictions: [1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0]\n",
            "Accuracy: 0.7714285714285715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/output_file.csv')\n",
        "\n",
        "df['age'] = df['age'] / 365.25\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df = df.drop(columns=['Name', 'Phone Number'])\n",
        "\n",
        "# Encode categorical columns\n",
        "categorical_columns = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
        "encoder = LabelEncoder()\n",
        "for col in categorical_columns:\n",
        "    df[col] = encoder.fit_transform(df[col])\n",
        "\n",
        "# Normalize numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(columns=['cardio']).values\n",
        "y = df['cardio'].values\n",
        "\n",
        "# Step 3: Split the dataset into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
        "\n",
        "# Step 4: Standardize the numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # Standardize training features\n",
        "X_test_scaled = scaler.transform(X_test)  # Standardize test features based on the training data\n",
        "\n",
        "# Step 5: Train the Logistic Regression model on non-encrypted data\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 6: Make predictions on the test dataset\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Step 7: Calculate accuracy metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the predictions and accuracy\n",
        "print(\"Predictions:\", y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a33yGyUN9dTF",
        "outputId": "f7822bcb-782d-462d-dc5f-69191a8e2f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1\n",
            " 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0]\n",
            "Accuracy: 0.7714285714285715\n"
          ]
        }
      ]
    }
  ]
}